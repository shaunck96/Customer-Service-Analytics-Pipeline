{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b25018df-8e50-4335-92de-6a6cecc08662",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     /home/spark-c48a6107-44ce-4987-a313-c9/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     /home/spark-c48a6107-44ce-4987-a313-c9/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\nYou can now load the package via spacy.load('en_core_web_sm')\nAll model files downloaded to temporary directory\nModel and tokenizer loaded successfully.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a7bc157de749bd89781ca13dddfa38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0544bdbe2a4b59b1e583ea65fbbde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.txt:   0%|          | 0.00/422k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ea78073abc4d61ad460c0cec862865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.13M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c8850884ca493db7a65d713e366de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/145M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All model files downloaded to temporary directory\nModel and tokenizer loaded successfully.\n[Gramformer] Grammar error correct/highlight                   model loaded..\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c041b134667d4fad964a49bb6a3d1ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/849 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1cbccb5d024d73bced3dae7a0c2944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ce614a68dd431da23a8b8f3970635a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/255 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80f75753ef34932bc2dc9ee53610ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21a4a7253884f9094d7231f4ebb867c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083ac7558f58407589572532463ede0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\nYou can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import base64\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "import huggingface_hub\n",
    "import librosa\n",
    "import nltk\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import requests\n",
    "import spacy\n",
    "import yaml\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from presidio_analyzer import AnalyzerEngine, EntityRecognizer, Pattern, PatternRecognizer\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "\n",
    "from cs_pa_nlp import WhisperModel, DBUtilConnectionCreator  # noqa: F403\n",
    "#from .faster_whisper import WhisperModel\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "class Gramformer:\n",
    "    def __init__(self,\n",
    "                 models=1,\n",
    "                 use_gpu=False,\n",
    "                 db=\"\",\n",
    "                 abfsClient=\"\",\n",
    "                 pytest_flag=True):\n",
    "        \"\"\"\n",
    "        Initialize the Gramformer object for grammar correction\n",
    "        and highlighting.\n",
    "\n",
    "        Args:\n",
    "            models (int): The number of models to use (1 or 2).\n",
    "            use_gpu (bool): Flag to indicate whether to use GPU for processing.\n",
    "            db (str): Database connection information.\n",
    "            abfsClient (str): Azure Blob Storage client.\n",
    "        \"\"\"\n",
    "        import errant\n",
    "        self.db = db\n",
    "        self.abfs_client = abfsClient\n",
    "        self.annotator = errant.load('en')\n",
    "        if use_gpu:\n",
    "            device = \"cuda:0\"\n",
    "        else:\n",
    "            device = \"cpu\"\n",
    "        self.device = device\n",
    "        self.model_loaded = False\n",
    "        self.pytest_flag = pytest_flag\n",
    "\n",
    "        if models == 1:\n",
    "            if self.pytest_flag is True:\n",
    "                model_path = (r\"C:\\Users\\307164\\Desktop\\deployment_for_bala\"\n",
    "                              r\"\\deployment_refactored\\cs_pa_nlp\\models\"\n",
    "                              r\"\\gramformer\")\n",
    "                self.c_t = AutoTokenizer.from_pretrained(\n",
    "                    model_path)\n",
    "                self.c_m = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "                    model_path)\n",
    "            else:\n",
    "                model_path = (r\"datascience/data/ds/sandbox\"\n",
    "                              r\"/shibushaun/huggingface_models\"\n",
    "                              r\"/gramformer\")\n",
    "                self.c_m, self.c_t = DBUtilConnectionCreator(  # noqa: F405\n",
    "                    self.db).download_and_load_gramformer_model(\n",
    "                        self.abfs_client, model_path)\n",
    "            self.c_m = self.c_m.to(device)\n",
    "            self.model_loaded = True\n",
    "            print(\"[Gramformer] Grammar error correct/highlight\\\n",
    "                   model loaded..\")\n",
    "        elif models == 2:\n",
    "            # TODO\n",
    "            print(\"TO BE IMPLEMENTED!!!\")\n",
    "\n",
    "    def correct(self, input_sentence, max_candidates=1):\n",
    "        \"\"\"\n",
    "        Correct grammar errors in the input sentence.\n",
    "\n",
    "        Args:\n",
    "            input_sentence (str): The input sentence with\n",
    "            potential grammar errors.\n",
    "            max_candidates (int): The maximum number of\n",
    "            corrected candidates to generate.\n",
    "\n",
    "        Returns:\n",
    "            set: A set of corrected sentences.\n",
    "\n",
    "        Uses the loaded Gramformer model to correct grammar errors\n",
    "        in the input sentence and returns a set of corrected sentences.\n",
    "        \"\"\"\n",
    "        if self.model_loaded:\n",
    "            correction_prefix = \"gec: \"\n",
    "            input_sentence = correction_prefix + input_sentence\n",
    "            input_ids = self.c_t.encode(\n",
    "                input_sentence, return_tensors='pt')\n",
    "            input_ids = input_ids.to(self.device)\n",
    "\n",
    "            preds = self.c_m.generate(\n",
    "                input_ids,\n",
    "                do_sample=True,\n",
    "                max_length=128,\n",
    "                num_beams=7,\n",
    "                early_stopping=True,\n",
    "                num_return_sequences=max_candidates)\n",
    "\n",
    "            corrected = set()\n",
    "            for pred in preds:\n",
    "                corrected.add(self.c_t.decode(\n",
    "                    pred, skip_special_tokens=True).strip())\n",
    "            return corrected\n",
    "        else:\n",
    "            print(\"Model is not loaded\")\n",
    "            return None\n",
    "\n",
    "    def highlight(self, orig, cor):\n",
    "        \"\"\"\n",
    "        Highlight grammar corrections in the original and corrected sentences.\n",
    "\n",
    "        Args:\n",
    "            orig (str): The original sentence.\n",
    "            cor (str): The corrected sentence.\n",
    "\n",
    "        Returns:\n",
    "            str: The original sentence with grammar corrections highlighted.\n",
    "\n",
    "        Highlights grammar corrections in\n",
    "        the original sentence\n",
    "        based on the corrected sentence and returns the highlighted text.\n",
    "        \"\"\"\n",
    "        edits = self._get_edits(orig, cor)\n",
    "        orig_tokens = orig.split()\n",
    "\n",
    "        ignore_indexes = []\n",
    "\n",
    "        for edit in edits:\n",
    "            edit_type = edit[0]\n",
    "            edit_str_start = edit[1]\n",
    "            edit_spos = edit[2]\n",
    "            edit_epos = edit[3]\n",
    "            edit_str_end = edit[4]\n",
    "\n",
    "            for i in range(edit_spos+1, edit_epos):\n",
    "                ignore_indexes.append(i)\n",
    "\n",
    "            if edit_str_start == \"\":\n",
    "                if edit_spos - 1 >= 0:\n",
    "                    new_edit_str = orig_tokens[edit_spos - 1]\n",
    "                    edit_spos -= 1\n",
    "                else:\n",
    "                    new_edit_str = orig_tokens[edit_spos + 1]\n",
    "                    edit_spos += 1\n",
    "                if edit_type == \"PUNCT\":\n",
    "                    st = \"<a type='\" + edit_type + \"' edit='\" + \\\n",
    "                        edit_str_end + \"'>\" + new_edit_str + \"</a>\"\n",
    "                else:\n",
    "                    st = \"<a type='\" + edit_type + \"' edit='\" + new_edit_str + \\\n",
    "                        \" \" + edit_str_end + \"'>\" + new_edit_str + \"</a>\"  # noqa: E501\n",
    "                orig_tokens[edit_spos] = st\n",
    "            elif edit_str_end == \"\":\n",
    "                st = \"<d type='\" + edit_type + \"' edit=''>\" + edit_str_start + \"</d>\"  # noqa: E501\n",
    "                orig_tokens[edit_spos] = st\n",
    "            else:\n",
    "                st = \"<c type='\" + edit_type + \"' edit='\" + \\\n",
    "                    edit_str_end + \"'>\" + edit_str_start + \"</c>\"\n",
    "                orig_tokens[edit_spos] = st\n",
    "\n",
    "        for i in sorted(ignore_indexes, reverse=True):\n",
    "            del (orig_tokens[i])\n",
    "\n",
    "        return (\" \".join(orig_tokens))\n",
    "\n",
    "    def detect(self, input_sentence):\n",
    "        # TO BE IMPLEMENTED\n",
    "        pass\n",
    "\n",
    "    def _get_edits(self, orig, cor):\n",
    "        \"\"\"\n",
    "        Get grammar edits between the original and corrected sentences.\n",
    "\n",
    "        Args:\n",
    "            orig (str): The original sentence.\n",
    "            cor (str): The corrected sentence.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of grammar edits as tuples.\n",
    "\n",
    "        Internal method to get grammar edits between the original\n",
    "        and corrected sentences and returns them as a list of tuples.\n",
    "        \"\"\"\n",
    "        orig = self.annotator.parse(orig)\n",
    "        cor = self.annotator.parse(cor)\n",
    "        alignment = self.annotator.align(orig, cor)\n",
    "        edits = self.annotator.merge(alignment)\n",
    "\n",
    "        if len(edits) == 0:\n",
    "            return []\n",
    "\n",
    "        edit_annotations = []\n",
    "        for e in edits:\n",
    "            e = self.annotator.classify(e)\n",
    "            edit_annotations.append((e.type[2:],\n",
    "                                     e.o_str,\n",
    "                                     e.o_start,\n",
    "                                     e.o_end,\n",
    "                                     e.c_str,\n",
    "                                     e.c_start,\n",
    "                                     e.c_end))\n",
    "\n",
    "        if len(edit_annotations) > 0:\n",
    "            return edit_annotations\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def get_edits(self, orig, cor):\n",
    "        \"\"\"\n",
    "        Get grammar edits between the original and corrected sentences.\n",
    "\n",
    "        Args:\n",
    "            orig (str): The original sentence.\n",
    "            cor (str): The corrected sentence.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of grammar edits as tuples.\n",
    "\n",
    "        Public method to get grammar edits\n",
    "        between the\n",
    "        original and corrected sentences and returns them as a list of tuples.\n",
    "        \"\"\"\n",
    "        return self._get_edits(orig, cor)\n",
    "\n",
    "\n",
    "class TitlesRecognizer(PatternRecognizer):\n",
    "    def __init__(self):\n",
    "        patterns = [r\"\\bMr\\.\\b\", r\"\\bMrs\\.\\b\", r\"\\bMiss\\b\"]\n",
    "        super().__init__(supported_entity=\"TITLE\", deny_list=patterns)\n",
    "\n",
    "\n",
    "class HFTransformersRecognizer(EntityRecognizer):\n",
    "    def __init__(self,\n",
    "                 model_id_or_path,\n",
    "                 supported_entities,\n",
    "                 supported_language=\"en\"):\n",
    "        self.pipeline = pipeline(\n",
    "            \"token-classification\",\n",
    "            model=model_id_or_path,\n",
    "            aggregation_strategy=\"simple\")\n",
    "        super().__init__(\n",
    "            supported_entities=supported_entities,\n",
    "            supported_language=supported_language)\n",
    "\n",
    "    def load(self):\n",
    "        pass\n",
    "\n",
    "    def analyze(self, text, entities=None, nlp_artifacts=None):\n",
    "        results = []\n",
    "        predictions = self.pipeline(text)\n",
    "        for prediction in predictions:\n",
    "            entity_type = prediction['entity_group']\n",
    "            if entities is None or entity_type in entities:\n",
    "                results.append(\n",
    "                    RecognizerResult(entity_type=entity_type,\n",
    "                                     start=prediction['start'],\n",
    "                                     end=prediction['end'],\n",
    "                                     score=prediction['score']))\n",
    "        return results\n",
    "\n",
    "\n",
    "class TextRedactor():\n",
    "    def __init__(self, model_dir):\n",
    "        self.model_dir = model_dir\n",
    "        self.analyzer = self.initialize_analyzer(self.model_dir)\n",
    "        self.anonymizer = AnonymizerEngine()\n",
    "\n",
    "    def initialize_analyzer(self, model_dir):\n",
    "        titles_recognizer = TitlesRecognizer()\n",
    "        transformers_recognizer = HFTransformersRecognizer(\n",
    "            model_id_or_path=model_dir,\n",
    "            supported_entities=[\"PERSON\", \"LOCATION\", \"ORGANIZATION\"])\n",
    "\n",
    "        phone_number_patterns = [Pattern(name=\"PHONE_NUMBER_REGEX\",\n",
    "                                         regex=r\"\\(?\\b\\d{3}\\)?[-.]?\\s?\\d{3}[-.]?\\s?\\d{4}\\b\",  # noqa: E501\n",
    "                                         score=0.5)]\n",
    "\n",
    "        email_patterns = [Pattern(name=\"EMAIL_REGEX\",\n",
    "                                  regex=r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\",  # noqa: E501\n",
    "                                  score=0.5)]\n",
    "        account_number_patterns = [Pattern(name=\"ACCOUNT_NUMBER_REGEX\",\n",
    "                                           regex=r\"\\b\\d{8,12}\\b\",\n",
    "                                           score=0.5)]\n",
    "\n",
    "        date_patterns = [Pattern(name=\"DATE_REGEX\",\n",
    "                                 regex=r\"\\b(?:\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\d{2,4}[-/]\\d{1,2}[-/]\\d{1,2}|\\b(?:January|February|March|April|May|June|July|August|September|October|November|December)\\b\\s\\d{1,2},?\\s\\d{4})\\b\",  # noqa: E501\n",
    "                                 score=0.5)]\n",
    "\n",
    "        address_patterns = [\n",
    "            Pattern(name=\"US_ADDRESS_REGEX_1\",\n",
    "                    regex=r\"\\b\\d{1,5}\\s([a-zA-Z\\s]{1,})\\b,?\\s([a-zA-Z\\s]{1,}),?\\s([A-Z]{2}),?\\s\\d{5}\\b\",  # noqa: E501\n",
    "                    score=0.85),\n",
    "        ]\n",
    "\n",
    "        ssn_patterns = [\n",
    "            Pattern(name=\"SSN_REGEX_FULL\",\n",
    "                    regex=r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\",  # noqa: E501\n",
    "                    score=0.85),\n",
    "            Pattern(name=\"SSN_REGEX_LAST4\",\n",
    "                    regex=r\"\\b\\d{4}\\b\",\n",
    "                    score=0.85)\n",
    "        ]\n",
    "        dollar_amount_patterns = [\n",
    "            Pattern(name=\"DOLLAR_AMOUNT_REGEX\",\n",
    "                    regex=r\"\\$\\s?\\d+(?:,\\d{3})*(?:\\.\\d{2})?\",  # noqa: E501\n",
    "                    score=0.6)\n",
    "\n",
    "        ]\n",
    "        bill_amount_patterns = [\n",
    "            Pattern(name=\"BILL_AMOUNT_REGEX\",\n",
    "                    regex=r\"\\b(?:payment|bill|amount)\\s?of\\s?\\$\\s?\\d+(?:,\\d{3})*(?:\\.\\d{2})?\",  # noqa: E501\n",
    "                    score=0.6)\n",
    "        ]\n",
    "        confirmation_number_patterns = [\n",
    "            Pattern(name=\"CONFIRMATION_NUMBER_REGEX\",\n",
    "                    regex=r\"confirmation\\snumber\\s(?:is\\s)?((?:\\d+|\\w+)(?:,\\s?(?:\\d+|\\w+))*)\",  # noqa: E501\n",
    "                    score=0.9)\n",
    "        ]\n",
    "\n",
    "        address_recognizer = PatternRecognizer(\n",
    "            supported_entity=\"ADDRESS\", patterns=address_patterns)\n",
    "        ssn_recognizer = PatternRecognizer(\n",
    "            supported_entity=\"US_SSN\", patterns=ssn_patterns)\n",
    "        phone_number_recognizer = PatternRecognizer(\n",
    "            supported_entity=\"PHONE_NUMBER\", patterns=phone_number_patterns)\n",
    "        email_recognizer = PatternRecognizer(\n",
    "            supported_entity=\"EMAIL_ADDRESS\", patterns=email_patterns)\n",
    "        account_number_recognizer = PatternRecognizer(\n",
    "            supported_entity=\"ACCOUNT_NUMBER\",\n",
    "            patterns=account_number_patterns)\n",
    "        date_recognizer = PatternRecognizer(\n",
    "            supported_entity=\"DATE\", patterns=date_patterns)\n",
    "        dollar_amount_recognizer = PatternRecognizer(\n",
    "            supported_entity=\"DOLLAR_AMOUNT\", patterns=dollar_amount_patterns)\n",
    "        bill_amount_recognizer = PatternRecognizer(\n",
    "            supported_entity=\"BILL_AMOUNT\", patterns=bill_amount_patterns)\n",
    "        confirmation_number_recognizer = PatternRecognizer(\n",
    "            supported_entity=\"CONFIRMATION_NUMBER\",\n",
    "            patterns=confirmation_number_patterns)\n",
    "\n",
    "        analyzer = AnalyzerEngine()\n",
    "        analyzer.registry.add_recognizer(titles_recognizer)\n",
    "        analyzer.registry.add_recognizer(transformers_recognizer)\n",
    "        analyzer.registry.add_recognizer(phone_number_recognizer)\n",
    "        analyzer.registry.add_recognizer(email_recognizer)\n",
    "        analyzer.registry.add_recognizer(account_number_recognizer)\n",
    "        analyzer.registry.add_recognizer(date_recognizer)\n",
    "        analyzer.registry.add_recognizer(address_recognizer)\n",
    "        analyzer.registry.add_recognizer(ssn_recognizer)\n",
    "        analyzer.registry.add_recognizer(dollar_amount_recognizer)\n",
    "        analyzer.registry.add_recognizer(bill_amount_recognizer)\n",
    "        analyzer.registry.add_recognizer(confirmation_number_recognizer)\n",
    "\n",
    "        return analyzer\n",
    "\n",
    "    def anonymize_text(self, input_text):\n",
    "        results = self.analyzer.analyze(text=input_text, language=\"en\")\n",
    "        anonymized_result = self.anonymizer.anonymize(\n",
    "            text=input_text,\n",
    "            analyzer_results=results)\n",
    "        return anonymized_result.text\n",
    "\n",
    "    def redact_text(self, input_text):\n",
    "        return self.anonymize_text(input_text)\n",
    "\n",
    "\n",
    "class AudioProcessor:\n",
    "    \"\"\"\n",
    "    Class for processing audio recordings,\n",
    "    transcribing them, and redacting PII.\n",
    "\n",
    "    Attributes:\n",
    "        abfs_client (str or AzureBlobFileSystem):\n",
    "        The Azure Blob Storage client.\n",
    "        pytest_flag (bool): Flag indicating whether running in pytest mode.\n",
    "        db: Database connection or reference.\n",
    "        config_file_path (str): Path to the configuration file.\n",
    "        account_sid (str): Twilio Account SID for API access.\n",
    "        auth_token (str): Twilio Auth Token for API access.\n",
    "        blob_directory (str): Directory path in Azure Blob Storage.\n",
    "        output_storage_path (str): Path for storing processed data.\n",
    "        date_created_before (pd.Timestamp): End date for audio recordings.\n",
    "        date_created_after (pd.Timestamp): Start date for audio recordings.\n",
    "        recording_names_list (list): List of recording names.\n",
    "        recording_url (str): URL for Twilio recordings API.\n",
    "        redaction_model (str): Model used for PII redaction.\n",
    "        tdf (pd.DataFrame):\n",
    "        DataFrame to store transcriptions and redacted data.\n",
    "        end_year (int): Year of the end date.\n",
    "        end_month (int): Month of the end date.\n",
    "        end_day (int): Day of the end date.\n",
    "        start_year (int): Year of the start date.\n",
    "        start_month (int): Month of the start date.\n",
    "        start_day (int): Day of the start date.\n",
    "        transcription_model: Whisper ASR model for transcription.\n",
    "        tokenizer: Tokenizer for the redaction model.\n",
    "        redaction_model: Model for token classification used in redaction.\n",
    "        db: Database connection or reference.\n",
    "\n",
    "    Methods:\n",
    "        __init__(self, abfs_client='ABFS', pytest_flag=False, db='')\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 abfs_client='ABFS',\n",
    "                 pytest_flag=False,\n",
    "                 db=\"\"):\n",
    "        \"\"\"\n",
    "        Initialize the AudioProcessor.\n",
    "\n",
    "        Args:\n",
    "            abfs_client (str or AzureBlobFileSystem):\n",
    "            The Azure Blob Storage client.\n",
    "            pytest_flag (bool): Flag indicating whether running in pytest mode.\n",
    "            db: Database connection or reference.\n",
    "        \"\"\"\n",
    "        self.pytest_flag = pytest_flag\n",
    "        self.abfs_client = abfs_client\n",
    "        self.db = db\n",
    "        if self.pytest_flag is False:\n",
    "            self.config_file_path = (r\"datascience/data/ds/sandbox\"\n",
    "                                     r\"/shibushaun/audio_processor_credentials\"\n",
    "                                     r\"/credentials_new.json\")\n",
    "            with self.abfs_client.open(self.config_file_path, 'r') as f:\n",
    "                config = json.load(f)\n",
    "                file_path = (r\"datascience/data/ds/sandbox\"\n",
    "                             r\"/shibushaun/huggingface_models/StanfordAIMI\"\n",
    "                             r\"/stanford-deidentifier-base\")\n",
    "\n",
    "                self.drm, self.drt = DBUtilConnectionCreator(  # noqa: F405\n",
    "                    self.db).download_and_load_redaction_model(\n",
    "                        self.abfs_client,\n",
    "                        file_path)\n",
    "\n",
    "        else:\n",
    "            self.config_file_path = (r\"C:\\Users\\307164\\Desktop\"\n",
    "                                     r\"\\deployment_for_bala\"\n",
    "                                     r\"\\deployment_refactored\"\n",
    "                                     r\"\\cs_pa_nlp\\credentials\"\n",
    "                                     r\"\\audio_processor_credentials.json\")\n",
    "\n",
    "            with open(self.config_file_path, 'r') as f:\n",
    "                config = json.load(f)\n",
    "                huggingface_hub.login(config['hf_token'])\n",
    "                self.drm_path = (r\"C:\\Users\\307164\\Desktop\"\n",
    "                                 r\"\\deployment_for_bala\"\n",
    "                                 r\"\\deployment_refactored\"\n",
    "                                 r\"\\cs_pa_nlp\\models\"\n",
    "                                 r\"\\stanford_deidentifier\")\n",
    "                self.drt = AutoTokenizer.from_pretrained(\n",
    "                    self.drm_path)\n",
    "                self.drm = AutoModelForTokenClassification.from_pretrained(\n",
    "                    self.drm_path)\n",
    "\n",
    "        self.account_sid = config.get(\"account_sid\")\n",
    "        self.auth_token = config.get(\"auth_token\")\n",
    "        self.blob_directory = config.get(\"blob_directory\")\n",
    "        self.output_storage_path = config.get(\"output_storage_path\")\n",
    "        self.date_created_before = pd.to_datetime(config.get(\"end_date\"))\n",
    "        self.date_created_after = pd.to_datetime(config.get(\"start_date\"))\n",
    "        self.recording_names_list = []\n",
    "        self.recording_url = (\n",
    "            \"https://api.twilio.com/2010-04-01/\"\n",
    "            f\"Accounts/{self.account_sid}/Recordings.json\"\n",
    "        )\n",
    "\n",
    "        self.tdf = pd.DataFrame(\n",
    "            columns=['recording_sid',\n",
    "                     'call_sid',\n",
    "                     'duration',\n",
    "                     'transcription',\n",
    "                     'redacted_transcription',\n",
    "                     'seg_tra'])\n",
    "\n",
    "        self.end_year = int(self.date_created_before.year)\n",
    "        self.end_month = int(self.date_created_before.month)\n",
    "        self.end_day = int(self.date_created_before.day)\n",
    "        self.start_year = int(self.date_created_after.year)\n",
    "        self.start_month = int(self.date_created_after.month)\n",
    "        self.start_day = int(self.date_created_after.day)\n",
    "        self.transcription_model = WhisperModel(\"base.en\", #tiny.en, tiny, base.en, base, small.en, small, medium.en, medium, large-v1, large-v2, distil-medium.en \t\n",
    "                                                device=\"cpu\",\n",
    "                                                compute_type=\"int8\", #int8, fp32\n",
    "                                                cpu_threads=8) \n",
    "        #model_size_or_path: str,\n",
    "        #device: str = \"auto\",\n",
    "        #device_index: Union[int, List[int]] = 0,\n",
    "        #compute_type: str = \"default\",\n",
    "        #cpu_threads: int = 0,\n",
    "        #num_workers: int = 1,\n",
    "        #download_root: Optional[str] = None,\n",
    "        #local_files_only: bool = False,\n",
    "\n",
    "        self.db = db\n",
    "        self.gf = Gramformer(models=1,\n",
    "                             use_gpu=False,\n",
    "                             db=self.db,\n",
    "                             abfsClient=self.abfs_client,\n",
    "                             pytest_flag=self.pytest_flag)\n",
    "        self.redactor = TextRedactor(\n",
    "            model_dir=\"Jean-Baptiste/roberta-large-ner-english\")\n",
    "        self.temp_log_file = \"\"\n",
    "        self.logger = self.setup_logger()\n",
    "        self.output_storage_path = config.get(\"output_storage_path\")\n",
    "\n",
    "    def setup_logger(self):\n",
    "        \"\"\"\n",
    "        Set up a logger for the AudioProcessor class.\n",
    "\n",
    "        This method creates a logger instance named\n",
    "        'AudioProcessor' and configures it to log messages at the DEBUG level.\n",
    "        It also creates a temporary log file to store the log messages.\n",
    "\n",
    "        Returns:\n",
    "            logging.Logger: The configured logger instance.\n",
    "\n",
    "        Note:\n",
    "            This method should be called to initialize\n",
    "            logging for the AudioProcessor class.\n",
    "\n",
    "        Example usage:\n",
    "            audio_processor = AudioProcessor()\n",
    "            logger = audio_processor.setup_logger()\n",
    "            logger.debug(\"This is a debug message\")\n",
    "\n",
    "        \"\"\"\n",
    "        logger = logging.getLogger('AudioProcessor')\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        self.temp_log_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "        handler = logging.FileHandler(self.temp_log_file.name)\n",
    "        formatter = logging.Formatter(\n",
    "            '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        return logger\n",
    "\n",
    "    def write_log_to_azure(self):\n",
    "        \"\"\"\n",
    "        Save the temporary log data to a permanent log file\n",
    "        and clean up resources.\n",
    "\n",
    "        This method flushes and seeks the temporary log file,\n",
    "        generates a unique log file name based on the current timestamp,\n",
    "        and saves the log data to a specified directory using\n",
    "        the Azure Blob FileSystem (ABFS) client. After saving, it prints\n",
    "        a success message and cleans up the temporary log file.\n",
    "\n",
    "        Note:\n",
    "            Ensure that the `self.temp_log_file` contains\n",
    "            the log data to be saved before calling this method.\n",
    "\n",
    "        Example usage:\n",
    "            audio_processor = AudioProcessor()\n",
    "            # ... Log some messages ...\n",
    "            audio_processor.save_logs_to_file()\n",
    "        \"\"\"\n",
    "        self.temp_log_file.flush()\n",
    "        self.temp_log_file.seek(0)\n",
    "        log_file_name = 'audio_processor_log' + datetime.datetime.now(\n",
    "\n",
    "        ).strftime(\n",
    "            \"%Y-%m-%d_%H-%M-%S\") + '.log'\n",
    "        if self.db == \"\":\n",
    "            path_to_log_file = (r\"C:\\Users\\307164\\Desktop\"\n",
    "                                r\"\\deployment_for_bala\"\n",
    "                                r\"\\deployment_refactored\"\n",
    "                                r\"\\cs_pa_nlp\\logs\")\n",
    "            with open(os.path.join(path_to_log_file,\n",
    "                                   log_file_name), 'wb') as log_file:\n",
    "                log_file.write(self.temp_log_file.read())\n",
    "        else:\n",
    "            path_to_log_file = \"datascience/data/ds/sandbox/shibushaun/logs\"\n",
    "            DBUtilConnectionCreator(  # noqa: F405\n",
    "                self.db).create_text_file(\n",
    "                    self.abfs_client,\n",
    "                    path_to_log_file,\n",
    "                    log_file_name, \"\")\n",
    "\n",
    "        with self.abfs_client.open(\n",
    "            os.path.join(path_to_log_file, log_file_name), 'wb'\n",
    "        ) as log_file:\n",
    "            log_file.write(self.temp_log_file.read())\n",
    "\n",
    "        print(\"Logs written to \"+path_to_log_file+\" successfully\")\n",
    "\n",
    "        self.temp_log_file.close()\n",
    "        os.unlink(self.temp_log_file.name)\n",
    "\n",
    "    def faster_transcriber(self, y):\n",
    "        \"\"\"\n",
    "        Transcribe audio segments using a faster transcription model.\n",
    "\n",
    "        Args:\n",
    "            y (str): Audio input for transcription.\n",
    "\n",
    "        Returns:\n",
    "            list of dict: List of transcription segments as\n",
    "            dictionaries with the following keys:\n",
    "                - 'start': Start time of the segment.\n",
    "                - 'end': End time of the segment.\n",
    "                - 'text': Transcribed text of the segment.\n",
    "                - 'no_speech_probability':\n",
    "                Probability of no speech in the segment.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If there is an error during transcription.\n",
    "\n",
    "        Example:\n",
    "            Usage:\n",
    "            >>> audio_processor = AudioProcessor()\n",
    "            >>> transcription_segments =\n",
    "            audio_processor.faster_transcriber(\"Sample audio input\")\n",
    "        \"\"\"\n",
    "        try:\n",
    "            segments, _ = self.transcription_model.transcribe(\n",
    "                y,\n",
    "                beam_size=5,\n",
    "                language=\"en\",\n",
    "                condition_on_previous_text=False,\n",
    "                vad_filter=True,\n",
    "                vad_parameters=dict(min_silence_duration_ms=500)\n",
    "            )\n",
    "\n",
    "            segments = list(segments)\n",
    "            segment_mapping_dict = {\n",
    "                2: 'start',\n",
    "                3: 'end',\n",
    "                4: 'text',\n",
    "                9: 'no_speech_probability'\n",
    "            }\n",
    "\n",
    "            transcriptions = []\n",
    "            for index in range(len(segments)):\n",
    "                transcription_dict = {}\n",
    "                for segment_index in list(segment_mapping_dict.keys()):\n",
    "                    transcription_dict[\n",
    "                        segment_mapping_dict[\n",
    "                            segment_index]] = segments[index][segment_index]\n",
    "                transcriptions.append(transcription_dict)\n",
    "\n",
    "            return transcriptions\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'Error in faster_transcriber: {str(e)}')\n",
    "            self.write_log_to_azure()\n",
    "            print(f\"Error in faster_transcriber: {str(e)}\")\n",
    "\n",
    "    def redact(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Redact PII from a text using a pre-trained NER model.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be redacted.\n",
    "\n",
    "        Returns:\n",
    "            str: Text with PII redacted.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            anonymized_text = self.redactor.redact_text(text)\n",
    "            return (anonymized_text)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'Error in redact: {str(e)}')\n",
    "            self.write_log_to_azure()\n",
    "            print(f\"Error in redact: {str(e)}\")\n",
    "\n",
    "    def replace_pii_with_stars(self,\n",
    "                               input_string: str,\n",
    "                               words_to_replace: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        Replace PII (Personally Identifiable Information)\n",
    "        with asterisks in a text.\n",
    "\n",
    "        Args:\n",
    "            input_string (str): The input text.\n",
    "            words_to_replace (List[str]): List of PII words to be redacted.\n",
    "\n",
    "        Returns:\n",
    "            str: Text with PII redacted.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            pattern = r'\\b(?:' + '|'.join(\n",
    "                re.escape(word) for word in words_to_replace) + r')\\b'\n",
    "            modified_string = re.sub(\n",
    "                pattern,\n",
    "                lambda match: '*' * len(match.group(0)),\n",
    "                input_string, flags=re.IGNORECASE)\n",
    "            return modified_string\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'Error in replace_pii_with_stars: {str(e)}')\n",
    "            self.write_log_to_azure()\n",
    "            print(f\"Error in replace_pii_with_stars: {str(e)}\")\n",
    "\n",
    "    def double_redact(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Redact PII from a text using a pre-trained NER model.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text to be redacted.\n",
    "\n",
    "        Returns:\n",
    "            str: Text with PII redacted.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            redact_pii_pipeline = pipeline(\n",
    "                \"ner\",\n",
    "                model=self.drm,\n",
    "                tokenizer=self.drt,\n",
    "                aggregation_strategy='average')\n",
    "            pii_words = [item['word'] for item in redact_pii_pipeline(text)]\n",
    "            modified_string = self.replace_pii_with_stars(text, pii_words)\n",
    "            return modified_string\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'Error in redact: {str(e)}')\n",
    "            self.write_log_to_azure()\n",
    "            print(f\"Error in redact: {str(e)}\")\n",
    "\n",
    "    def grammar_corrector(self, transcription):\n",
    "        \"\"\"\n",
    "        Correct grammar in a given transcription.\n",
    "\n",
    "        This method takes a transcription as input,\n",
    "        splits it into sentences, and attempts to correct the grammar for each\n",
    "        sentence using a grammar correction tool (self.gf).\n",
    "        It then joins the corrected sentences and returns the resulting\n",
    "        corrected transcription.\n",
    "\n",
    "        Args:\n",
    "            transcription (str): The transcription text to be corrected.\n",
    "\n",
    "        Returns:\n",
    "            str: The corrected transcription with improved grammar.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If an error occurs during the\n",
    "            grammar correction process,\n",
    "            it is logged and an error message is printed.\n",
    "\n",
    "        Example usage:\n",
    "            audio_processor = AudioProcessor()\n",
    "            transcription = \"I has a apple. She run fast.\"\n",
    "            corrected_transcription =\n",
    "            audio_processor.grammar_corrector(transcription)\n",
    "            print(corrected_transcription)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            influent_sentences = re.compile('[.!?] ').split(transcription)\n",
    "            corrected_transcription = \"\"\n",
    "\n",
    "            for influent_sentence in influent_sentences:\n",
    "                corrected_sentences = list(\n",
    "                    self.gf.correct(\n",
    "                        influent_sentence,\n",
    "                        max_candidates=1))  # Convert set to list\n",
    "                corrected_sentence = corrected_sentences[\n",
    "                    0] if corrected_sentences else influent_sentence\n",
    "                corrected_transcription += \"\".join(corrected_sentence)\n",
    "\n",
    "                corrected_transcription += \" \"\n",
    "\n",
    "            return corrected_transcription\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'Error in grammar_corrector: {str(e)}')\n",
    "            self.write_log_to_azure()\n",
    "            print(f\"Error in grammar_corrector: {str(e)}\")\n",
    "\n",
    "    def get_request_issuer(self, auth_header_encoded):\n",
    "        \"\"\"\n",
    "        Make requests to the Twilio API to fetch audio\n",
    "        recordings and perform transcriptions.\n",
    "\n",
    "        This function sends requests to the Twilio API to\n",
    "        retrieve audio recordings based on specified date filters.\n",
    "        It transcribes the audio recordings and stores the\n",
    "        transcriptions in a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            auth_header_encoded (str): Encoded authorization\n",
    "            header for Twilio API authentication.\n",
    "\n",
    "        Raises:\n",
    "            Exception: An exception is raised if any error\n",
    "            occurs during the process.\n",
    "\n",
    "        Returns:\n",
    "            None: This function does not return a value but\n",
    "            performs various operations and data storage.\n",
    "\n",
    "        Note:\n",
    "            - The function relies on external libraries such\n",
    "            as requests, librosa, and custom methods like faster_transcriber.\n",
    "            - It requires the configuration of Twilio credentials,\n",
    "            Azure storage, and other settings.\n",
    "            - The behavior of the function is\n",
    "            influenced by the value of 'pytest_flag'.\n",
    "\n",
    "        Example usage:\n",
    "            auth_header_encoded = \"Base64EncodedAuthorizationHeader\"\n",
    "            instance = YourClass()\n",
    "            instance.get_request_issuer(auth_header_encoded)\n",
    "        \"\"\"\n",
    "        date_created_before = datetime.datetime(self.end_year,\n",
    "                                                self.end_month,\n",
    "                                                self.end_day,\n",
    "                                                tzinfo=datetime.timezone.utc)\n",
    "        date_created_after = datetime.datetime(self.start_year,\n",
    "                                               self.start_month,\n",
    "                                               self.start_day,\n",
    "                                               tzinfo=datetime.timezone.utc)\n",
    "\n",
    "        recording_url = (\n",
    "                    \"https://api.twilio.com/2010-04-01/\"\n",
    "                    f\"Accounts/{self.account_sid}/Recordings.json\"\n",
    "                )\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                recording_url,\n",
    "                auth=(self.account_sid, self.auth_token),\n",
    "                headers={\"Authorization\": f\"Basic {auth_header_encoded}\"},\n",
    "                params={\"date_created<=\": date_created_before.isoformat(),\n",
    "                        \"date_created>=\": date_created_after.isoformat(),\n",
    "                        \"PageSize\": 40,\n",
    "                        },\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                for recording in response.json()['recordings']:\n",
    "                    recording_sid = recording['sid']\n",
    "                    recording_url = recording['media_url']\n",
    "\n",
    "                    duration = recording['duration']\n",
    "                    call_sid = recording['call_sid']\n",
    "\n",
    "                    recording_extension = 'mp3'\n",
    "\n",
    "                    response = requests.get(\n",
    "                        recording_url,\n",
    "                        auth=(self.account_sid, self.auth_token),\n",
    "                        headers={\"Authorization\":\n",
    "                                 f\"Basic {auth_header_encoded}\"},\n",
    "                    )\n",
    "\n",
    "                    if response.ok:\n",
    "                        if int(duration) > 60:\n",
    "                            if self.pytest_flag is False:\n",
    "                                filename = os.path.join(\n",
    "                                    self.blob_directory,\n",
    "                                    f'{recording_sid}.{recording_extension}')\n",
    "                                with self.abfs_client.open(filename,\n",
    "                                                           'wb') as f:\n",
    "                                    f.write(response.content)\n",
    "                                print(f'Recording saved to {filename}')\n",
    "                                with self.abfs_client.open(filename,\n",
    "                                                           'rb') as f:\n",
    "                                    y, sr = librosa.load(f)\n",
    "                                print(\"Transcription for\\\n",
    "                                       call: \"+call_sid+\" has begun\")\n",
    "                                start = time.time()\n",
    "                                tra = self.faster_transcriber(y)\n",
    "                                print(\"Time for Transcription\\\n",
    "                                       of call: \"+str(time.time()-start))\n",
    "                                print(\"Call Duration: \"+str(duration))\n",
    "                                print(\"\\n\\n\")\n",
    "                                transcriptions_text = \"\"\n",
    "                                for index in range(len(tra)):\n",
    "                                    transcriptions_text += tra[\n",
    "                                        index]['text']\n",
    "                                transcriptions_text = self.grammar_corrector(\n",
    "                                    transcriptions_text)\n",
    "                                red_text = self.redact(\n",
    "                                    transcriptions_text)\n",
    "                                red_text = self.double_redact(\n",
    "                                    red_text)\n",
    "                                print(\"Transcribed Text: \"+transcriptions_text)\n",
    "                                print(\"Redacted Transcribed \\\n",
    "                                      Text: \"+red_text)\n",
    "                                self.tdf = self.tdf.append(\n",
    "                                    {'recording_sid': recording_sid,\n",
    "                                     'call_sid': call_sid,\n",
    "                                     'duration': duration,\n",
    "                                     'transcription': transcriptions_text,\n",
    "                                     'redacted_transcription': red_text,\n",
    "                                     'seg_tra': tra}, ignore_index=True)\n",
    "                                print(f\"File {filename}\\\n",
    "                                       has been \\\n",
    "                                      sdeleted after transcription.\")\n",
    "                                import gc\n",
    "                                gc.collect()\n",
    "                            else:\n",
    "                                filename = os.path.join(\n",
    "                                    self.blob_directory,\n",
    "                                    f'{recording_sid}.{recording_extension}')\n",
    "                                with open(filename, 'wb') as f:\n",
    "                                    f.write(response.content)\n",
    "                                print(f'Recording saved to {filename}')\n",
    "                                with open(filename, 'rb') as f:\n",
    "                                    y, sr = librosa.load(f)\n",
    "                                tra = self.faster_transcriber(y)\n",
    "                                transcriptions_text = \"\"\n",
    "                                for index in range(len(tra)):\n",
    "                                    transcriptions_text += tra[\n",
    "                                        index]['text']\n",
    "                                red_text = self.redact(\n",
    "                                    transcriptions_text)\n",
    "                                red_text = self.double_redact(\n",
    "                                    red_text)\n",
    "                                if not hasattr(self,  # noqa: F405\n",
    "                                               'tdf') or self.tdf is None:\n",
    "                                    self.tdf = pd.DataFrame(\n",
    "                                        columns=['recording_sid',\n",
    "                                                 'call_sid',\n",
    "                                                 'duration',\n",
    "                                                 'transcription',\n",
    "                                                 'redacted_transcription',\n",
    "                                                 'seg_tra'])\n",
    "                                dta = {\n",
    "                                    'recording_sid': recording_sid,\n",
    "                                    'call_sid': call_sid,\n",
    "                                    'duration': duration,\n",
    "                                    'transcription': transcriptions_text,\n",
    "                                    'redacted_transcription': red_text,\n",
    "                                    'seg_tra': tra\n",
    "                                }\n",
    "\n",
    "                                self.tdf = pd.concat(\n",
    "                                    [self.tdf,\n",
    "                                     pd.DataFrame([\n",
    "                                         dta])], ignore_index=True)\n",
    "                    else:\n",
    "                        print(f'Failed to retrieve \\\n",
    "                            recording SID {recording_sid}')\n",
    "            else:\n",
    "                print(f'Failed to save transcribed redacted recordings. \\\n",
    "                    Status code: {response.status_code}')\n",
    "\n",
    "            if self.pytest_flag is False:\n",
    "                self.db.write_df_to_azure(self.abfs_client,\n",
    "                                          input_file=self.tdf,\n",
    "                                          azure_path=self.output_storage_path,\n",
    "                                          format=\"csv\",\n",
    "                                          verbose=True)\n",
    "            else:\n",
    "                self.tdf.to_csv(self.output_storage_path)\n",
    "                print(\"Redacted Transcriptions have been successfully saved\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'Error in grammar_corrector: {str(e)}')\n",
    "            self.write_log_to_azure()\n",
    "            print(f\"Error in grammar_corrector: {str(e)}\")\n",
    "\n",
    "    def transcription_redaction_trigger(self):\n",
    "        \"\"\"\n",
    "        Connect to external services, transcribe audio,\n",
    "        and redact PII in transcriptions.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: A DataFrame containing\n",
    "            transcriptions and redacted transcriptions.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.authorization_header_prepper()\n",
    "            return self.tdf\n",
    "            import gc\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f'Error in \\\n",
    "                              transcription_redaction_trigger: {str(e)}')\n",
    "            self.write_log_to_azure()\n",
    "            print(f\"Error in transcription_redaction_trigger: {str(e)}\")\n",
    "\n",
    "db = DBUtilConnectionCreator(dbutils=dbutils)\n",
    "abfsClient = db.get_abfs_client()\n",
    "ap = AudioProcessor(abfs_client = abfsClient, \n",
    "                    pytest_flag=False, \n",
    "                    db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d67d515d-580c-48c9-a255-410e8898ff56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/Workspace/Users/sshibu@pplweb.com/CS_PA_NLP/mp3_files/production_calls/6019532.wav\", 'rb'):\n",
    "    y, sr = librosa.load(\"/Workspace/Users/sshibu@pplweb.com/CS_PA_NLP/mp3_files/production_calls/6018705.wav\")\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "transcription = ap.faster_transcriber(y)\n",
    "\n",
    "print(\"Transcription: \"+str(transcription))\n",
    "print(\"Duration of the Call: \"+str(duration))\n",
    "print(\"Transcription Time: \"+str(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0878c00e-8725-4f42-be9b-78adf082166c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 744.1270294784581\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "num_workers = 4\n",
    "\n",
    "folder_path = \"/Workspace/Users/sshibu@pplweb.com/CS_PA_NLP/mp3_files/production_calls/\"\n",
    "all_files_in_folder = os.listdir(folder_path)\n",
    "files = []\n",
    "\n",
    "for file_name in all_files_in_folder:\n",
    "    complete_file_path = os.path.join(folder_path, file_name)\n",
    "    files.append(complete_file_path)\n",
    "\n",
    "files_reqd = files[25:26] #[5:10]\n",
    "\n",
    "#files = [\n",
    "#    \"/Workspace/Users/sshibu@pplweb.com/CS_PA_NLP/mp3_files/production_calls/6018705.wav\",\n",
    "#    \"/Workspace/Users/sshibu@pplweb.com/CS_PA_NLP/mp3_files/production_calls/6019226.wav\",\n",
    "#    \"/Workspace/Users/sshibu@pplweb.com/CS_PA_NLP/mp3_files/production_calls/6019247.wav\",\n",
    "#    \"/Workspace/Users/sshibu@pplweb.com/CS_PA_NLP/mp3_files/production_calls/6019323.wav\",\n",
    "#]\n",
    "\n",
    "\n",
    "def transcribe_file(file_path):\n",
    "    y, sr = librosa.load(file_path)\n",
    "    duration = librosa.get_duration(y=y, sr=sr)\n",
    "    print(\"Duration: \"+str(duration))\n",
    "    tra = ap.faster_transcriber(y)\n",
    "    transcriptions_text = \"\".join([t['text'] for t in tra])\n",
    "    #corrected_text = ap.grammar_corrector(transcriptions_text)\n",
    "    #redacted_text = ap.double_redact(ap.redact(corrected_text))\n",
    "    redacted_text = ap.double_redact(ap.redact(transcriptions_text))\n",
    "    return redacted_text\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(num_workers) as executor:\n",
    "    start = time.time()\n",
    "    results = list(executor.map(transcribe_file, files_reqd))\n",
    "    print(results)\n",
    "    print(f\"Transcription, Grammar Correction and Redaction Time for {str(len(files_reqd))} calls: \"+str(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f5e6af3-d729-414a-bf70-545139329412",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "files_reqd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "075da465-1ff0-4d66-8eff-e036390dcd29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Whisper Transcription Time Benchmarking",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
